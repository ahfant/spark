{"paragraphs":[{"text":"%md\n# End-to-End Workflow using Decision Tree\n\nUsing mushroom dataset from <https://archive.ics.uci.edu/ml/datasets/Mushroom>\n\nThis notebook describes the basic workflow consisting of the following phases:\n\n1. Prepare Spark Environment\n2. Prepare Data\n    1. Read Data\n    2. Review Data\n    3. Transform Data\n        1. Transform Label\n        2. Transform Features\n        3. Assemble Features\n3. Create Train-Test Split\n4. Create Machine Learning Object\n5. Create Pipeline\n6. Train Machine Learning Object\n7. Evaluate Trained Machine Learning Object\n    1. Perform Predictions\n    2. Compute Accuracy\n    3. Display Trained Model","dateUpdated":"2017-11-01T13:40:58+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h1>End-to-End Workflow using Decision Tree</h1>\n<p>Using mushroom dataset from <a href=\"https://archive.ics.uci.edu/ml/datasets/Mushroom\">https://archive.ics.uci.edu/ml/datasets/Mushroom</a></p>\n<p>This notebook describes the basic workflow consisting of the following phases:</p>\n<ol>\n<li>Prepare Spark Environment</li>\n<li>Prepare Data<ol>\n<li>Read Data</li>\n<li>Review Data</li>\n<li>Transform Data<ol>\n<li>Transform Label</li>\n<li>Transform Features</li>\n<li>Assemble Features</li>\n</ol>\n</li>\n</ol>\n</li>\n<li>Create Train-Test Split</li>\n<li>Create Machine Learning Object</li>\n<li>Create Pipeline</li>\n<li>Train Machine Learning Object</li>\n<li>Evaluate Trained Machine Learning Object<ol>\n<li>Perform Predictions</li>\n<li>Compute Accuracy</li>\n<li>Display Trained Model</li>\n</ol>\n</li>\n</ol>\n"}]},"apps":[],"jobName":"paragraph_1509537242351_1320176658","id":"20171101-124938_1410235252","dateCreated":"2017-11-01T12:54:02+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5662","user":"anonymous","dateFinished":"2017-11-01T13:40:58+0100","dateStarted":"2017-11-01T13:40:58+0100"},{"text":"%md\n## 1. Prepare Spark Environment","dateUpdated":"2017-11-01T13:40:58+0100","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>1. Prepare Spark Environment</h2>\n"}]},"apps":[],"jobName":"paragraph_1509537242352_1330564878","id":"20171101-125022_810908129","dateCreated":"2017-11-01T12:54:02+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5663","user":"anonymous","dateFinished":"2017-11-01T13:40:58+0100","dateStarted":"2017-11-01T13:40:58+0100"},{"text":"%spark2.pyspark\nfrom __future__ import print_function\nimport sys\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\nprint(\"Spark version:\", spark.version)\nprint(\"Python version:\", sys.version)","dateUpdated":"2017-11-01T13:40:58+0100","config":{"tableHide":false,"editorSetting":{"language":"python","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/python","editorHide":true,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Spark version: 2.1.0.2.6.0.3-8\nPython version: 2.7.6 (default, Oct 26 2016, 20:30:19) \n[GCC 4.8.4]\n"}]},"apps":[],"jobName":"paragraph_1509537242352_1330564878","id":"20171101-125211_1210780886","dateCreated":"2017-11-01T12:54:02+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5665","user":"anonymous","dateFinished":"2017-11-01T13:40:58+0100","dateStarted":"2017-11-01T13:40:58+0100"},{"text":"%md\n## 2. Prepare Data","dateUpdated":"2017-11-01T13:40:58+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509537242353_1330180129","id":"20171101-125233_1608542200","dateCreated":"2017-11-01T12:54:02+0100","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:5666","user":"anonymous","dateFinished":"2017-11-01T13:40:58+0100","dateStarted":"2017-11-01T13:40:58+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>2. Prepare Data</h2>\n"}]}},{"text":"%md\n## 2.1. Read Data from HDFS\n\n- data format: csv\n- header row: true\n- infer schema automatically: true\n\nusing <https://spark.apache.org/docs/2.1.1/api/python/pyspark.sql.html#module-pyspark.sql>","user":"anonymous","dateUpdated":"2017-11-01T13:40:58+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509537623567_-931057555","id":"20171101-130023_372409444","dateCreated":"2017-11-01T13:00:23+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6313","dateFinished":"2017-11-01T13:40:58+0100","dateStarted":"2017-11-01T13:40:58+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>2.1. Read Data from HDFS</h2>\n<ul>\n<li>data format: csv</li>\n<li>header row: true</li>\n<li>infer schema automatically: true</li>\n</ul>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.1/api/python/pyspark.sql.html#module-pyspark.sql\">https://spark.apache.org/docs/2.1.1/api/python/pyspark.sql.html#module-pyspark.sql</a></p>\n"}]}},{"text":"%spark2.pyspark\n\n# returns a DataFrame\ndf = spark.read.format(\"csv\")\\\n            .option(\"header\", \"true\")\\\n            .option(\"inferSchema\", \"true\")\\\n            .load(\"hdfs:///user/sooyam/workshop/mushrooms.csv\")\n\ndf","user":"anonymous","dateUpdated":"2017-11-01T13:40:58+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509537654504_-1428107162","id":"20171101-130054_1977702845","dateCreated":"2017-11-01T13:00:54+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6387","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DataFrame[class: string, cap-shape: string, cap-surface: string, cap-color: string, bruises: string, odor: string, gill-attachment: string, gill-spacing: string, gill-size: string, gill-color: string, stalk-shape: string, stalk-root: string, stalk-surface-above-ring: string, stalk-surface-below-ring: string, stalk-color-above-ring: string, stalk-color-below-ring: string, veil-type: string, veil-color: string, ring-number: string, ring-type: string, spore-print-color: string, population: string, habitat: string]\n"}]}},{"text":"%md\n## 2.2. Review Data\n\nusing <https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame>","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509537698187_1185369523","id":"20171101-130138_1325824727","dateCreated":"2017-11-01T13:01:38+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6460","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>2.2. Review Data</h2>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame\">https://spark.apache.org/docs/2.1.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame</a></p>\n"}]}},{"text":"%spark2.pyspark\nprint(\"Number of data rows:\", df.count())\n\ndf.printSchema() # or data.dtypes or df.columns\n\ndf.describe(\"class\", \"cap-shape\", \"cap-surface\", \"cap-color\").show()","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509537704451_1198851059","id":"20171101-130144_1955506359","dateCreated":"2017-11-01T13:01:44+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6525","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"('Number of data rows:', 8124)\nroot\n |-- class: string (nullable = true)\n |-- cap-shape: string (nullable = true)\n |-- cap-surface: string (nullable = true)\n |-- cap-color: string (nullable = true)\n |-- bruises: string (nullable = true)\n |-- odor: string (nullable = true)\n |-- gill-attachment: string (nullable = true)\n |-- gill-spacing: string (nullable = true)\n |-- gill-size: string (nullable = true)\n |-- gill-color: string (nullable = true)\n |-- stalk-shape: string (nullable = true)\n |-- stalk-root: string (nullable = true)\n |-- stalk-surface-above-ring: string (nullable = true)\n |-- stalk-surface-below-ring: string (nullable = true)\n |-- stalk-color-above-ring: string (nullable = true)\n |-- stalk-color-below-ring: string (nullable = true)\n |-- veil-type: string (nullable = true)\n |-- veil-color: string (nullable = true)\n |-- ring-number: string (nullable = true)\n |-- ring-type: string (nullable = true)\n |-- spore-print-color: string (nullable = true)\n |-- population: string (nullable = true)\n |-- habitat: string (nullable = true)\n\n+-------+-----+---------+-----------+---------+\n|summary|class|cap-shape|cap-surface|cap-color|\n+-------+-----+---------+-----------+---------+\n|  count| 8124|     8124|       8124|     8124|\n|   mean| null|     null|       null|     null|\n| stddev| null|     null|       null|     null|\n|    min|    e|        b|          f|        b|\n|    max|    p|        x|          y|        y|\n+-------+-----+---------+-----------+---------+\n\n"}]}},{"text":"%md\n## 2.3. Transform Data\n\nThis is a three-step process:\n(1) Transform label\n(2) Transform features\n(3) Assemble features\n\n- <b>pyspark.ml.feature.StringIndexer:</b> a label indexer that maps a string column of labels to an ML column of label indices.\n- <b>pyspark.ml.feature.VectorIndexer:</b> for indexing categorical feature columns in a dataset of Vector.\n- <b>pyspark.ml.feature.VectorAssembler:</b> a transformer that combines a given list of columns into a single vector column\n\nusing <https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#module-pyspark.ml.feature>","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509537772917_1300332824","id":"20171101-130252_352398640","dateCreated":"2017-11-01T13:02:52+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6637","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>2.3. Transform Data</h2>\n<p>This is a three-step process:\n<br  />(1) Transform label\n<br  />(2) Transform features\n<br  />(3) Assemble features</p>\n<ul>\n<li><b>pyspark.ml.feature.StringIndexer:</b> a label indexer that maps a string column of labels to an ML column of label indices.</li>\n<li><b>pyspark.ml.feature.VectorIndexer:</b> for indexing categorical feature columns in a dataset of Vector.</li>\n<li><b>pyspark.ml.feature.VectorAssembler:</b> a transformer that combines a given list of columns into a single vector column</li>\n</ul>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#module-pyspark.ml.feature\">https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#module-pyspark.ml.feature</a></p>\n"}]}},{"text":"%md\n## 2.3.1. Transform Label\n- Using <b>StringIndexer</b>\n    - Index labels, adding metadata to the label column","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509538152649_184680318","id":"20171101-130912_716496499","dateCreated":"2017-11-01T13:09:12+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:6913","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>2.3.1. Transform Label</h2>\n<ul>\n<li>Using <b>StringIndexer</b><ul>\n<li>Index labels, adding metadata to the label column</li>\n</ul>\n</li>\n</ul>\n"}]}},{"text":"%spark2.pyspark\n\nlabelIndexer = StringIndexer(inputCol=\"class\", outputCol=\"indexedLabel\")","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":true},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509538249778_707492776","id":"20171101-131049_1451250388","dateCreated":"2017-11-01T13:10:49+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7042","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n##2.3.2. Transform Features\n- Using <b>StringIndexer</b>\n    - Because VectorIndexer does not allow strings","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509538365537_747707521","id":"20171101-131245_1876696527","dateCreated":"2017-11-01T13:12:45+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7188","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>2.3.2. Transform Features</h2>\n<ul>\n<li>Using <b>StringIndexer</b><ul>\n<li>Because VectorIndexer does not allow strings</li>\n</ul>\n</li>\n</ul>\n"}]}},{"text":"%spark2.pyspark\n\ncategorical_columns = df.columns[1:]\n\nfeatureIndexers = [StringIndexer(inputCol=col, outputCol='stringindexed_' + col) for col in categorical_columns]","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509538560782_959936195","id":"20171101-131600_1945470487","dateCreated":"2017-11-01T13:16:00+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7401","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n## 2.3.3. Assemble Features\n- Using <b>VectorAssembler</b>\n    - Combine features in a single vector column\n","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509538579414_2059209776","id":"20171101-131619_576362585","dateCreated":"2017-11-01T13:16:19+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7474","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>2.3.3. Assemble Features</h2>\n<ul>\n<li>Using <b>VectorAssembler</b><ul>\n<li>Combine features in a single vector column</li>\n</ul>\n</li>\n</ul>\n"}]}},{"user":"anonymous","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509538632693_780566587","id":"20171101-131712_221603571","dateCreated":"2017-11-01T13:17:12+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7560","text":"%spark2.pyspark\n\ninputFeatures = ['stringindexed_' + col for col in categorical_columns]\n\nassembler = VectorAssembler(\n                inputCols=inputFeatures,\n                outputCol=\"indexedFeatures\")","dateUpdated":"2017-11-01T13:40:59+0100","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n## 3. Create Train-Test-Split\n\n- Split the data into training and test sets (e.g. 30% held out for testing)\n- Use seed=1234 for reproducibility\n\nusing <https://spark.apache.org/docs/2.1.1/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit>\n","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509538657429_-343639051","id":"20171101-131737_1003320471","dateCreated":"2017-11-01T13:17:37+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:7647","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>3. Create Train-Test-Split</h2>\n<ul>\n<li>Split the data into training and test sets (e.g. 30% held out for testing)</li>\n<li>Use seed=1234 for reproducibility</li>\n</ul>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.1/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit\">https://spark.apache.org/docs/2.1.1/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit</a></p>\n"}]}},{"text":"%spark2.pyspark\n\n(trainingData, testData) = df.randomSplit([0.7, 0.3], 1234)","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":true},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509538970423_201746066","id":"20171101-132250_1291624127","dateCreated":"2017-11-01T13:22:50+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8051","dateFinished":"2017-11-01T13:41:00+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n## 4. Create Machine Learning Object\n- Create a Decision Tree model\n\nusing <https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassifier>","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539011498_554438214","id":"20171101-132331_2036612814","dateCreated":"2017-11-01T13:23:31+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8143","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>4. Create Machine Learning Object</h2>\n<ul>\n<li>Create a Decision Tree model</li>\n</ul>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassifier\">https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassifier</a></p>\n"}]}},{"text":"%spark2.pyspark\n\nclf = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":true},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539055082_-577215570","id":"20171101-132415_250666329","dateCreated":"2017-11-01T13:24:15+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8231","dateFinished":"2017-11-01T13:41:00+0100","dateStarted":"2017-11-01T13:41:00+0100","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n\n## 5. Create Pipeline\n\nChain indexers and model in a Pipeline\n1. labelIndexer\n2. featureIndexers\n3. assembler\n4. clf\n\nusing <https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.Pipeline>","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539066661_-1980394809","id":"20171101-132426_780877803","dateCreated":"2017-11-01T13:24:26+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8305","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>5. Create Pipeline</h2>\n<p>Chain indexers and model in a Pipeline</p>\n<ol>\n<li>labelIndexer</li>\n<li>featureIndexers</li>\n<li>assembler</li>\n<li>clf</li>\n</ol>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.Pipeline\">https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.Pipeline</a></p>\n"}]}},{"text":"%spark2.pyspark\n\npipeline = Pipeline(stages=[labelIndexer] + featureIndexers + [assembler, clf])","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539115464_816036818","id":"20171101-132515_1753495955","dateCreated":"2017-11-01T13:25:15+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8392","dateFinished":"2017-11-01T13:41:00+0100","dateStarted":"2017-11-01T13:41:00+0100","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n\n## 6. Train Machine Learning Object\n\n- Execute the stages in the pipeline including featurization and model training on test data\n\nusing <https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.Pipeline.fit>","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539163549_1116803188","id":"20171101-132603_548219344","dateCreated":"2017-11-01T13:26:03+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8500","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>6. Train Machine Learning Object</h2>\n<ul>\n<li>Execute the stages in the pipeline including featurization and model training on test data</li>\n</ul>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.Pipeline.fit\">https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.Pipeline.fit</a></p>\n"}]}},{"text":"%spark2.pyspark\n\nmodel = pipeline.fit(trainingData)","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":true},"editorMode":"ace/mode/python","editorHide":false,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539209656_-1984444801","id":"20171101-132649_1392302485","dateCreated":"2017-11-01T13:26:49+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8557","dateFinished":"2017-11-01T13:41:05+0100","dateStarted":"2017-11-01T13:41:00+0100","results":{"code":"SUCCESS","msg":[]}},{"text":"%md\n\n## 7. Evaluate Trained Machine Learning Object","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539222887_262504099","id":"20171101-132702_1851520580","dateCreated":"2017-11-01T13:27:02+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8631","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>7. Evaluate Trained Machine Learning Object</h2>\n"}]}},{"text":"%md\n## 7.1. Perform Predictions\n\n- Perform predictions against the test data by using transform\n\nusing <https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.PipelineModel.transform>","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539386891_-1939735664","id":"20171101-132946_688145385","dateCreated":"2017-11-01T13:29:46+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8916","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>7.1. Perform Predictions</h2>\n<ul>\n<li>Perform predictions against the test data by using transform</li>\n</ul>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.PipelineModel.transform\">https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.PipelineModel.transform</a></p>\n"}]}},{"text":"%spark2.pyspark\n\npredictions = model.transform(testData)\n\n# Select example rows to display.\npredictions.select(\"prediction\", \"indexedLabel\", \"indexedFeatures\").show(5)","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python","editOnDblClick":false},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539276390_988433329","id":"20171101-132756_852114580","dateCreated":"2017-11-01T13:27:56+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8720","dateFinished":"2017-11-01T13:41:05+0100","dateStarted":"2017-11-01T13:41:00+0100","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"+----------+------------+--------------------+\n|prediction|indexedLabel|     indexedFeatures|\n+----------+------------+--------------------+\n|       0.0|         0.0|(22,[0,1,2,6,8,9,...|\n|       0.0|         0.0|(22,[0,1,2,6,8,9,...|\n|       0.0|         0.0|(22,[0,1,2,6,8,9,...|\n|       0.0|         0.0|(22,[0,1,2,6,8,9,...|\n|       0.0|         0.0|(22,[0,1,2,6,8,9,...|\n+----------+------------+--------------------+\nonly showing top 5 rows\n\n"}]}},{"text":"%md\n\n## 7.2. Compute Accuracy\n\n- Compute accuracy against the test data using Evaluator\n\nusing <https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator>","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539863725_1488262666","id":"20171101-133743_1896901548","dateCreated":"2017-11-01T13:37:43+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9064","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>7.2. Compute Accuracy</h2>\n<ul>\n<li>Compute accuracy against the test data using Evaluator</li>\n</ul>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator\">https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.evaluation.MulticlassClassificationEvaluator</a></p>\n"}]}},{"text":"%spark2.pyspark\n\nevaluator = MulticlassClassificationEvaluator(\n                labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\naccuracy = evaluator.evaluate(predictions)\nprint(\"Test set accuracy = \" + str(accuracy))","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"python"},"editorMode":"ace/mode/python"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539309929_-1554341504","id":"20171101-132829_2146814255","dateCreated":"2017-11-01T13:28:29+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:8811","dateFinished":"2017-11-01T13:41:06+0100","dateStarted":"2017-11-01T13:41:05+0100","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"Test set accuracy = 0.998755703028\n"}]}},{"text":"%md\n\n## 7.3 Display Trained Model\n\n- Display trained decision tree\n\nusing <https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassificationModel.toDebugString>","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"markdown","editOnDblClick":true},"editorMode":"ace/mode/markdown","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509539960030_417845253","id":"20171101-133920_735218970","dateCreated":"2017-11-01T13:39:20+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9168","dateFinished":"2017-11-01T13:40:59+0100","dateStarted":"2017-11-01T13:40:59+0100","results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<h2>7.3 Display Trained Model</h2>\n<ul>\n<li>Display trained decision tree</li>\n</ul>\n<p>using <a href=\"https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassificationModel.toDebugString\">https://spark.apache.org/docs/2.1.1/api/python/pyspark.ml.html#pyspark.ml.classification.DecisionTreeClassificationModel.toDebugString</a></p>\n"}]}},{"text":"%spark2.pyspark\n\ntreeModel = model.stages[-1] # last stage in Pipeline\n# summary only\nprint(treeModel.toDebugString)","user":"anonymous","dateUpdated":"2017-11-01T14:27:43+0100","config":{"colWidth":12,"enabled":true,"results":{"0":{"graph":{"mode":"table","height":448,"optionOpen":false}}},"editorSetting":{"language":"python","editOnDblClick":true},"editorMode":"ace/mode/python","editorHide":true,"tableHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509540025036_197242927","id":"20171101-134025_1451790514","dateCreated":"2017-11-01T13:40:25+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9252","dateFinished":"2017-11-01T13:41:06+0100","dateStarted":"2017-11-01T13:41:06+0100","results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"DecisionTreeClassificationModel (uid=DecisionTreeClassifier_44dcbdb5047d2fd3632b) of depth 5 with 13 nodes\n  If (feature 4 in {0.0,4.0,5.0,8.0})\n   If (feature 19 in {0.0,1.0,2.0,3.0,5.0,6.0,7.0,8.0})\n    If (feature 14 in {0.0,1.0,2.0,3.0,5.0,6.0})\n     If (feature 14 in {0.0,1.0,2.0,5.0,6.0})\n      If (feature 21 in {0.0,1.0,2.0,4.0,5.0,6.0})\n       Predict: 0.0\n      Else (feature 21 not in {0.0,1.0,2.0,4.0,5.0,6.0})\n       Predict: 0.0\n     Else (feature 14 not in {0.0,1.0,2.0,5.0,6.0})\n      If (feature 10 in {0.0})\n       Predict: 0.0\n      Else (feature 10 not in {0.0})\n       Predict: 1.0\n    Else (feature 14 not in {0.0,1.0,2.0,3.0,5.0,6.0})\n     Predict: 1.0\n   Else (feature 19 not in {0.0,1.0,2.0,3.0,5.0,6.0,7.0,8.0})\n    Predict: 1.0\n  Else (feature 4 not in {0.0,4.0,5.0,8.0})\n   Predict: 1.0\n\n"}]}},{"text":"","user":"anonymous","dateUpdated":"2017-11-01T13:40:59+0100","config":{"colWidth":12,"enabled":true,"results":{},"editorSetting":{"language":"scala"},"editorMode":"ace/mode/scala"},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1509540044487_1771097435","id":"20171101-134044_2014877842","dateCreated":"2017-11-01T13:40:44+0100","status":"FINISHED","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:9326"}],"name":"sooyam/workshop","id":"2CW1W86C9","angularObjects":{"2C9T8P13D:shared_process":[],"2CDBY4T9E:shared_process":[],"2C9NXCYHF:shared_process":[],"2CA2MW6AR:shared_process":[],"2CA5PJTU1:shared_process":[],"2C97256Y6:shared_process":[],"2CAGUJPNY:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}